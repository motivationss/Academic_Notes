\chapter{Production Problem}
\lecture{3}{8 Sep. 08:00}{Production Problem}
\section{Production Problem}
The \emph{production problem} can be formulated as follows.
\begin{align*}
	\max~ & c^{\top}x     \\
	      & Ax \leq b     \\
	      & x\geq \vec{0}
\end{align*}
\begin{itemize}
	\item \(n\) products activities
	\item \(c_{j}=\) per-unit revenue for activity \(j = 1\ldots n\)
	\item \(b_{i}=\) resource endowment for resource \(i = 1\ldots m\)
	\item \(a_{ij}=\) amount of resource \(i\) consumed by activity \(j\)
\end{itemize}

\section{Norm}
We start with some definitions.
\begin{definition}
	We define the following different norms.
	\begin{definition}[Maximum norm]\label{def:maximum-norm}
		The \emph{maximum norm} is defined as
		\[
			\left\lVert x\right\rVert_{\infty } \coloneqq \max_{1\leq i \leq n}\{\left\vert x_i \right\vert \}.
		\]
	\end{definition}
	\begin{definition}[\(1\)-norm]\label{def:1-norm}
		The \emph{\(1\)-norm} is defined as
		\[
			\left\lVert x\right\rVert_{1} \coloneqq \sum\limits_{i=1}^{n} \left\vert x_i \right\vert.
		\]
	\end{definition}
	\begin{definition}[\(2\)-norm]\label{def:2-norm}
		The \emph{\(2\)-norm} is defined as
		\[
			\left\lVert x\right\rVert_{2} \coloneqq \sqrt{\sum\limits_{i=1}^{n} x_i^2}.
		\]
	\end{definition}
\end{definition}

We can easily find the respective norm for \(x\) by following linear optimization problems.

\subsection{Maximum (Infinity) Norm}
Consider
\begin{align*}
	\min~ & \left\lVert x\right\rVert_{\infty } \\
	      & Ax = b,
\end{align*}
we set up
\begin{align*}
	\min~ & t                                      \\
	      & t\geq x_i,\text{ for }i = 1, \ldots ,n \\
	      & t\leq x_i,\text{ for }i = 1, \ldots ,n \\
	      & Ax = b.
\end{align*}

We see that the linear optimization \textbf{pressure} will force the maximum of \(\left\vert x_i \right\vert \) being small, hence
we'll get the minimum among \(\left\vert x_i \right\vert \).

\subsection{1-Norm}
Consider
\begin{align*}
	\min~ & \left\lVert x\right\rVert_1 \\
	      & Ax = b,
\end{align*}
we set up
\[
	\begin{alignedat}{3}
		\min~ & \sum\limits_{i=1}^{n} t_i                \\
		& t_i\geq x_i, && \text{ for }i = 1, \ldots ,n  \\
		& t_i\leq -x_i, && \text{ for }i = 1, \ldots ,n \\
		& Ax = b.
	\end{alignedat}
\]

Again, we see that the linear optimization pressure will force \(t_i\) goes to \(\left\vert x_i \right\vert \), resulting
\(\sum\limits_{i=1}^{n} t_i\) being \(\left\lVert x\right\rVert_1\).

\begin{remark}
	Minimize \(\left\lVert x\right\rVert_1\) tends to make \(x\) \textbf{spars} (lots of zeros).
	\begin{figure}[H]
		\centering
		\incfig{1-norm}
		\caption{The best approximated convex function of \(I_{x = 0}\) }
		\label{fig:1-norm}
	\end{figure}
\end{remark}
